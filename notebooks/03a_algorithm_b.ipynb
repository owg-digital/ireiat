{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96d94dbe-1089-47df-9adc-82082d427c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns',None)\n",
    "import itertools\n",
    "from functools import partial\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from typing import Set, Tuple, List, Dict, Optional\n",
    "import igraph\n",
    "import random\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from pickle import load\n",
    "import time\n",
    "import networkx as nx\n",
    "from zipfile import ZipFile\n",
    "import os\n",
    "import pyogrio\n",
    "import dyntapy\n",
    "from sklearn.neighbors import BallTree\n",
    "import warnings\n",
    "# requires local installation of ireiat package using \n",
    "from ireiat.util.cacheable import CACHE_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b81a90-5999-48bb-8e4f-452fc7f53a3e",
   "metadata": {},
   "source": [
    "# What this notebook does (or is meant to do) [WIP]\n",
    "\n",
    "We solve a traffic assignment problem using dyntapy for a subset of O-Ds. To do this, we:\n",
    "\n",
    "1. Make a transport network with the right attributes for algorithm B\n",
    "    * Parse the FAF5 links data into a basic highway network\n",
    "       * Free flow speed [miles/hour]?\n",
    "       * Capacity (!) [tons/hour]? <-- not quite sure how we'll find this\n",
    "       * Length [miles]\n",
    "       * Lanes [count] <-- does not seem to matter for algorithm B\n",
    "    * Do some checks on connectivity for use with algorithm B\n",
    "    * Serialize that network\n",
    "5. Make an OD graph between counties with the right connectors\n",
    "    * Take an (optional) subset of the county-county OD flows to create an OD graph\n",
    "    * Pick the number of connectors and the location of connectors within each county\n",
    "    * Create an OD graph with the right attributes\n",
    "    * Serialize the result\n",
    "9. Solve a static assignment problem and save the results\n",
    "    * Load the serialized highway network\n",
    "    * Add the connectors to the highway network\n",
    "    * Relabel the graph\n",
    "    * Create a StaticAssignment\n",
    "    * Solve the traffic assignment problem using Algorithm B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4cdce5b-231b-4faa-b0d7-b1b6fd41be65",
   "metadata": {},
   "outputs": [],
   "source": [
    "round_to_digits = partial(round,ndigits=6) #helper function to standardize lat long precision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1911c352-2869-4fa7-ac3e-028e39e3f618",
   "metadata": {},
   "source": [
    "### Make a transport network with the right attributes for algorithm B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aff6a9f9-bef2-4674-b599-24260e28fb8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 8.53 s\n",
      "Wall time: 8.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "target_path = CACHE_PATH / 'data/raw/fa5_highway_links.zip'\n",
    "# note pyogrio provides like a gajillion time speedup when reading big .shp files (11s vs. 326s with geopandas)\n",
    "faf5_links_gdf = pyogrio.read_dataframe(target_path, use_arrow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ae341bd-f922-4b93-af60-f7cab8378eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 3.12 s\n",
      "Wall time: 3.11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "faf5_links_gdf = faf5_links_gdf.to_crs(\"EPSG:4326\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8eef753b-8684-4039-8dbb-d687fddbb409",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_faf5_links_gdf = faf5_links_gdf.loc[~faf5_links_gdf['state'].isin(['AK','HI'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18718f18-4a35-444a-9c37-2455631f63c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes 346,170 and edges 968,892\n",
      "CPU times: total: 15.9 s\n",
      "Wall time: 15.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "nx_highway_graph = nx.DiGraph()\n",
    "node_idx_dict: Dict[Tuple[float,float],int] = dict()\n",
    "node_idx_counter = 0\n",
    "edge_idx_counter = 0\n",
    "for row in subset_faf5_links_gdf.itertuples():\n",
    "    # get the origin and destination identifiers (the nodes)\n",
    "    origin_longitude, origin_latitude = map(round_to_digits,  row.geometry.coords[0])\n",
    "    destination_longitude, destination_latitude = map(round_to_digits,  row.geometry.coords[-1])\n",
    "\n",
    "    # add the node indices to the dictionary if they don't exist\n",
    "    if (origin_latitude,origin_longitude) not in node_idx_dict:\n",
    "        node_idx_dict[(origin_latitude,origin_longitude)] = node_idx_counter\n",
    "        node_idx_counter +=1\n",
    "    if (destination_latitude, destination_longitude) not in node_idx_dict:\n",
    "        node_idx_dict[(destination_latitude,destination_longitude)] = node_idx_counter\n",
    "        node_idx_counter +=1\n",
    "\n",
    "    origin_node_idx = node_idx_dict[(origin_latitude,origin_longitude)]\n",
    "    destination_node_idx = node_idx_dict[(destination_latitude,destination_longitude)]\n",
    "\n",
    "    # add the nodes with the right attributese to be used by dyntapy\n",
    "    nx_highway_graph.add_node(origin_node_idx, x_coord=origin_longitude, y_coord=origin_latitude)\n",
    "    nx_highway_graph.add_node(destination_node_idx, x_coord=destination_longitude, y_coord=destination_latitude)\n",
    "\n",
    "    # add the edges with the right attributes to be used by dyntapy\n",
    "    # ‘from_node_id’, ‘to_node_id’, ‘link_id’, ‘lanes’, ‘capacity’, ‘length’, ‘free_speed’\n",
    "    length_miles = row.length\n",
    "    ab_lanes = 1 if (np.isnan(row.ab_lanes) or row.ab_lanes<1) else row.ab_lanes # many links have NaN or 0 lanes\n",
    "    ba_lanes = 1 if (np.isnan(row.ba_lanes) or row.ba_lanes<1) else row.ba_lanes\n",
    "    ab_edge = {\n",
    "        'u_of_edge':origin_node_idx, \n",
    "        'v_of_edge':destination_node_idx,\n",
    "        'from_node_id':origin_node_idx, \n",
    "        'to_node_id':destination_node_idx,\n",
    "        'lanes':ab_lanes,\n",
    "        'length':length_miles,\n",
    "        'free_speed':row.ab_finalsp, # still not sure of this\n",
    "        'capacity':ab_lanes*22000    \n",
    "    }\n",
    "    ba_edge = {\n",
    "        'u_of_edge':destination_node_idx, \n",
    "        'v_of_edge':origin_node_idx,\n",
    "        'from_node_id':destination_node_idx, \n",
    "        'to_node_id':origin_node_idx,\n",
    "        'lanes':ba_lanes,\n",
    "        'length':length_miles,\n",
    "        'free_speed':row.ba_finalsp, # still not sure of this\n",
    "        'capacity':ba_lanes*22000   \n",
    "    }\n",
    "    \n",
    "    if row.dir==1: # A-> B only\n",
    "        ab_edge[\"link_id\"]=edge_idx_counter\n",
    "        nx_highway_graph.add_edge(**ab_edge)\n",
    "        edge_idx_counter += 1\n",
    "\n",
    "        # create a fictitious edge\n",
    "        ba_edge[\"link_id\"]=edge_idx_counter\n",
    "        ba_edge['lanes'] = 1\n",
    "        ba_edge['free_speed'] = 1\n",
    "        ba_edge['capacity'] = 1\n",
    "        nx_highway_graph.add_edge(**ba_edge)\n",
    "        edge_idx_counter += 1\n",
    "    \n",
    "    elif row.dir==-1: # B->A only\n",
    "        ba_edge[\"link_id\"]=edge_idx_counter\n",
    "        nx_highway_graph.add_edge(**ba_edge)\n",
    "        edge_idx_counter += 1\n",
    "\n",
    "        # create a fictitious edge\n",
    "        ab_edge[\"link_id\"]=edge_idx_counter\n",
    "        ab_edge['lanes'] = 1\n",
    "        ab_edge['free_speed'] = 1\n",
    "        ab_edge['capacity'] = 1\n",
    "        nx_highway_graph.add_edge(**ab_edge)\n",
    "        edge_idx_counter += 1\n",
    "    \n",
    "    else:\n",
    "        # add A->B\n",
    "        ab_edge[\"link_id\"]=edge_idx_counter\n",
    "        nx_highway_graph.add_edge(**ab_edge)\n",
    "        edge_idx_counter += 1\n",
    "\n",
    "        # add B->A\n",
    "        ba_edge[\"link_id\"]=edge_idx_counter\n",
    "        nx_highway_graph.add_edge(**ba_edge)\n",
    "        edge_idx_counter += 1\n",
    "\n",
    "print(f\"Nodes {node_idx_counter:,} and edges {edge_idx_counter:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "666e929b-579a-4aa0-93f6-9a4e3a98cb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for subsequent lookup by node id\n",
    "idx_node_dict = {v:k for k,v in node_idx_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62894dc6-388d-44a2-b8b0-022e39144c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is graph strongly connected: False\n",
      "Number of strongly connected components 152\n"
     ]
    }
   ],
   "source": [
    "print(f\"Is graph strongly connected: {nx.is_strongly_connected(nx_highway_graph)}\")\n",
    "print(f\"Number of strongly connected components {len([x for x in nx.strongly_connected_components(nx_highway_graph)]):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42811907-ae83-4fa7-8718-41f14a952388",
   "metadata": {},
   "source": [
    "### Make an OD graph between counties with the right connectors\n",
    "\n",
    "Inputs:\n",
    "  * Pre-computed county-county flows (in ktons)\n",
    "  * County .shp files (to get the geometry of the counties)\n",
    "\n",
    "Outputs:\n",
    "  * The location (latitude, longitude) of the connectors that will be used to attach to the transport graph (.pickle file)\n",
    "  * A networkx graph with attributes formatted according to dyntapy needs to solve static assignment\n",
    "    \n",
    "This procedure requires us to to make assumptions on:\n",
    "  * How many points in the county demand will originate from (assumed 1 in the current implementation)\n",
    "  * Where in the county demand will originate from (assumed the geographic centroid in the current implementation)\n",
    "\n",
    "We can change these calculation assumptions but will still need to generate the two outputs to solve the static assignment problem\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6fd51cad-c6bd-4b3a-bcd6-60c9fa1dcd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input 1\n",
    "county_od = pd.read_parquet('../data/transformed/county_od.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea1d8519-4894-44bb-972c-e3c0c77ba0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input 2\n",
    "target_path = CACHE_PATH /  'data/raw/us_county_shp_files.zip'\n",
    "county_gdf = pyogrio.read_dataframe(target_path, use_arrow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe0e22a3-ce47-4a9a-909f-33b9cc292ecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98353"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's start with a small portion of the ODs to see if we can get it to work\n",
    "OD_QUANTILE_THRESHOLD = .99\n",
    "# OD_QUANTILE_THRESHOLD = None\n",
    "if OD_QUANTILE_THRESHOLD:\n",
    "    tons_threshold = county_od['tons'].quantile(OD_QUANTILE_THRESHOLD)\n",
    "    subset_county_od = county_od.loc[county_od['tons'] > tons_threshold]\n",
    "else:\n",
    "    subset_county_od = county_od\n",
    "len(subset_county_od)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a93763c2-3aca-4206-baff-885432787d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we need to figure out where in each county we want a \"connector\" [a location from which tons will attach to the transport graph]\n",
    "# right now, we're using the \"actual\" geometric centroid as the \"connector\" location  in the county but we could refine this in the future\n",
    "# based on where in the county we expect things to be originating from and/or how many \"connectors\" we want to have within each county\n",
    "county_gdf = county_gdf.to_crs(\"EPSG:5070\") # albers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92c9f5a5-33a0-452e-b672-b721cf04eef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "county_gdf['centroid'] = county_gdf.geometry.centroid.to_crs(\"EPSG:4326\") # in lat/long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3dbca97a-5c73-4597-98c4-ef526c3239fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 78.1 ms\n",
      "Wall time: 73 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# create a dict of (statefp,countyfp) => connector latitude, connector longitude [right now this is only using a SINGLE connector]\n",
    "county_to_node_dict = dict()\n",
    "county_to_node_idx_dict = dict()\n",
    "for idx, row in enumerate(county_gdf.itertuples()):\n",
    "    county_to_node_dict[(row.STATEFP,row.COUNTYFP)]=(round_to_digits(row.centroid.y), round_to_digits(row.centroid.x))\n",
    "    county_to_node_idx_dict[(row.STATEFP,row.COUNTYFP)] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88f29089-130d-447e-b25a-ce906b4429cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OD graph: num nodes (3,041), edges (98,353)\n",
      "CPU times: total: 297 ms\n",
      "Wall time: 286 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "od_graph = nx.DiGraph()\n",
    "for row in subset_county_od.itertuples():\n",
    "    # get the origin and destination identifiers\n",
    "    origin_node, destination_node = (row.state_orig, row.county_orig), (row.state_dest, row.county_dest)\n",
    "\n",
    "    # extract the node latitudes and longitudes and indices from pre-computed dictionaries\n",
    "    origin_latitude, origin_longitude = county_to_node_dict[origin_node]\n",
    "    destination_latitude, destination_longitude = county_to_node_dict[destination_node]\n",
    "    origin_node_idx = county_to_node_idx_dict[origin_node]\n",
    "    destination_node_idx =  county_to_node_idx_dict[destination_node]\n",
    "\n",
    "    # add the nodes and edges with the right attributese to be used by dyntapy\n",
    "    od_graph.add_node(origin_node_idx, x_coord=origin_longitude, y_coord=origin_latitude)\n",
    "    od_graph.add_node(destination_node_idx, x_coord=destination_longitude, y_coord=destination_latitude)\n",
    "    od_graph.add_edge(origin_node_idx, destination_node_idx, flow=row.tons)\n",
    "\n",
    "print(f\"OD graph: num nodes ({len(od_graph.nodes):,}), edges ({len(od_graph.edges):,})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "858e7813-35cd-439d-9f1d-11190b10aade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 422 ms\n",
      "Wall time: 401 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# serialize the OD graph\n",
    "nx.write_gml(od_graph, CACHE_PATH / \"data/transformed/county_od_graph.gml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "968defa1-82a8-4f6f-ac13-46d10c98c6f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 3.39 s\n",
      "Wall time: 3.37 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# test that we can reload the OD graph\n",
    "od_graph = nx.read_gml(CACHE_PATH / \"data/transformed/county_od_graph.gml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d6ce4a-71cc-4780-b0a2-2a6b824258ad",
   "metadata": {},
   "source": [
    "### Solve algorithm B using the highway network and the OD graph that we've previously serialized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bbc030e0-282d-4ac8-93dd-c18043c0f05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "centroid_x = np.array([row.centroid.x for row in county_gdf.itertuples()])\n",
    "centroid_y = np.array([row.centroid.y for row in county_gdf.itertuples()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5bf0ce5a-6930-416d-86f9-69d0962765d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to find where on the highway graph to connect the centroids\n",
    "# construct a ball tree based on the highway graph data\n",
    "highway_node_lat_long_radians = np.deg2rad(np.array(list(node_idx_dict.keys())))\n",
    "highway_node_ball_tree = BallTree(highway_node_lat_long_radians, metric='haversine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6e25cbc2-a55f-47e9-b60a-722f589213df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the centroid locations\n",
    "RADIUS_EARTH_MILES = 3958.8\n",
    "centroid_lat_longs = [(lat,long) for lat,long in zip(centroid_y,centroid_x)]\n",
    "centroid_radians = np.deg2rad(centroid_lat_longs)\n",
    "distances_radians, centroid_idx_to_hwy_node_idx = highway_node_ball_tree.query(centroid_radians,k=1)\n",
    "distances_miles = distances_radians.squeeze()*RADIUS_EARTH_MILES\n",
    "centroid_idx_to_hwy_node_idx = centroid_idx_to_hwy_node_idx.squeeze() # make a 1-D array\n",
    "\n",
    "# add the centroids and associated links to the highway graph\n",
    "augmented_nx_highway_graph = nx_highway_graph.copy()\n",
    "DEFAULT_CONNECTOR_LANES = 10\n",
    "DEFAULT_CONNECTOR_CAPACITY = 1e6\n",
    "DEFAULT_CONNECTOR_SPEED = 200\n",
    "\n",
    "for (centroid_lat, centroid_long), dist, hwy_node_idx in zip(centroid_lat_longs, distances_miles, centroid_idx_to_hwy_node_idx):\n",
    "    # add the centroid node\n",
    "    augmented_nx_highway_graph.add_node(node_idx_counter, x_coord=centroid_long, y_coord=centroid_lat, centroid=\"true\")\n",
    "    node_idx_dict[(centroid_lat,centroid_long)] = node_idx_counter\n",
    "    connected_node_latitude, connected_node_longitude = idx_node_dict[hwy_node_idx]\n",
    "\n",
    "    # add source and sink connectors\n",
    "    source_data = {\n",
    "        'u_of_edge':node_idx_counter, \n",
    "        'v_of_edge':hwy_node_idx,\n",
    "        'from_node_id':node_idx_counter, \n",
    "        'to_node_id':hwy_node_idx,\n",
    "        'lanes':DEFAULT_CONNECTOR_LANES,\n",
    "        'length':dist,\n",
    "        'free_speed':DEFAULT_CONNECTOR_SPEED,\n",
    "        'capacity':DEFAULT_CONNECTOR_CAPACITY,\n",
    "        'connector':True,\n",
    "        \"link_type\": np.int8(1),\n",
    "    }\n",
    "    sink_data = {\n",
    "        'u_of_edge':hwy_node_idx, \n",
    "        'v_of_edge':node_idx_counter,\n",
    "        'from_node_id':hwy_node_idx, \n",
    "        'to_node_id':node_idx_counter,\n",
    "        'lanes':DEFAULT_CONNECTOR_LANES,\n",
    "        'length':dist,\n",
    "        'free_speed':DEFAULT_CONNECTOR_SPEED,\n",
    "        'capacity':DEFAULT_CONNECTOR_CAPACITY,\n",
    "        'connector':True,\n",
    "        \"link_type\": np.int8(-1),\n",
    "    }\n",
    "    node_idx_counter +=1 # we have added a node at the top\n",
    "    augmented_nx_highway_graph.add_edge(**source_data)\n",
    "    augmented_nx_highway_graph.add_edge(**sink_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f750c91-3b16-43af-9b83-6d124d3ab5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_nx_hwy_graph_relabeled = dyntapy.relabel_graph(augmented_nx_highway_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3311b7f4-ec83-40b7-b236-10d9fe43ccc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nicholas.padon\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\dyntapy\\supply_data.py:456: UserWarning: Network contains very long links, up to 4895.42919921875 km. Implementation has not been verified forthis type of network. calculations may yield unexpected results.\n",
      "  warn(\n",
      "C:\\Users\\nicholas.padon\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\dyntapy\\demand.py:117: UserWarning: intra-zonal traffic is ignored\n",
      "  warn(\"intra-zonal traffic is ignored\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init passed successfully\n",
      "CPU times: total: 47.5 s\n",
      "Wall time: 47.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sa = dyntapy.assignments.StaticAssignment(augmented_nx_hwy_graph_relabeled, od_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "96d729f3-d453-40bf-86c0-6b43c80019e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:1\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\dyntapy\\assignments.py:297\u001b[0m, in \u001b[0;36mStaticAssignment.run\u001b[1;34m(self, method, store_iterations, **kwargs)\u001b[0m\n\u001b[0;32m    295\u001b[0m tolls \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtolls\u001b[39m\u001b[38;5;124m\"\u001b[39m, np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minternal_network\u001b[38;5;241m.\u001b[39mtot_links))\n\u001b[0;32m    296\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdial_b\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 297\u001b[0m     costs, destination_flows, gap_definition, gap \u001b[38;5;241m=\u001b[39m \u001b[43mdial_b\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minternal_network\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minternal_demand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore_iterations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolls\u001b[49m\n\u001b[0;32m    299\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    300\u001b[0m     flows \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(destination_flows, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    301\u001b[0m     result \u001b[38;5;241m=\u001b[39m StaticResult(\n\u001b[0;32m    302\u001b[0m         costs,\n\u001b[0;32m    303\u001b[0m         flows,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    309\u001b[0m         destination_flows\u001b[38;5;241m=\u001b[39mdestination_flows,\n\u001b[0;32m    310\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\dyntapy\\graph_utils.py:135\u001b[0m, in \u001b[0;36m_get_link_id\u001b[1;34m()\u001b[0m\n\u001b[0;32m    133\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _id\n\u001b[0;32m    134\u001b[0m \u001b[38;5;66;03m# (from_node, to_node) not set in out_links\u001b[39;00m\n\u001b[1;32m--> 135\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = sa.run(method='dial_b') # uses numba, so first run needs compilation time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e47c7be-ab42-4499-9e96-0483684e2480",
   "metadata": {},
   "source": [
    "# Garbage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed865a93-ef78-4bac-84d9-d9fa114afee2",
   "metadata": {},
   "source": [
    "1. Methods for stuff\n",
    "\n",
    "* all or nothing assignment [naive \"lowest\" impedance path for each O-D pair. does not take into account congestion]\n",
    "* sequential congestion assignment [order-dependent! not straighforwardly parallelizable. not obvious what the congestion function is...]\n",
    "* probablistic assignment on top k \"low impedance\" candidate paths [picking candidates is hard]\n",
    "* really cool convex programming problem [intractable]\n",
    "    - for all flow paths between O-D, have some power (quadratic?) cost function with constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74590747-1436-4b93-b2c9-aeeda0078028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 13.6 s\n",
      "Wall time: 13.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 6th decimal place is 0.11m in lat/long. IF you go to greater granularity you still get the same number of nodes\n",
    "# https://gis.stackexchange.com/questions/8650/measuring-accuracy-of-latitude-and-longitude\n",
    "\n",
    "def map_start_end_lat_long(row):\n",
    "    \"\"\" Each LINESTRING object consists of lat/longs - and the bounds get the extreme endpoints\"\"\"\n",
    "    long_start, lat_start = map(round_to_digits,  row.geometry.coords[0])\n",
    "    long_end, lat_end = map(round_to_digits,  row.geometry.coords[-1])\n",
    "    # return (row.objectid, row.length, (lat_start, long_start), (lat_end, long_end))\n",
    "    if row.dir==1: # A-> B only\n",
    "        return [(row.objectid, row.length, row.ctfips, (lat_start, long_start), (lat_end, long_end))]\n",
    "    elif row.dir==-1: # B->A only\n",
    "        return [(row.objectid, row.length, row.ctfips, (lat_end, long_end), (lat_start, long_start))]\n",
    "    else:\n",
    "        return [(row.objectid, row.length, row.ctfips, (lat_start, long_start), (lat_end, long_end)),\n",
    "                (row.objectid, row.length, row.ctfips, (lat_end, long_end), (lat_start, long_start))]\n",
    "\n",
    "\n",
    "# we iterate through the set of links in parallel, extracting formatted endpoints\n",
    "edge_data = list(itertools.chain.from_iterable([map_start_end_lat_long(row) for row in faf5_links_gdf.itertuples()]))\n",
    "# edge_data = [map_start_end_lat_long(row) for row in faf5_links_gdf.itertuples()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3158f57f-567b-4918-8535-e76c4e615bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of county to node dicts\n",
    "county_to_node_dict = defaultdict(list)\n",
    "for obj, length, ctfips, lat_long_start, lat_long_end in edge_data:\n",
    "    if ctfips:\n",
    "        state, county = ctfips[:2], ctfips[2:]\n",
    "        county_to_node_dict[(state,county)].append(lat_long_start)\n",
    "        county_to_node_dict[(state,county)].append(lat_long_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d6567ab-c9bc-4e65-8ac6-8d12d180393e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the formatted endpoints, we create unique nodes, indexed from 0\n",
    "node_set: Set[Tuple[float, float]] = {(lat,long) for record in edge_data for lat,long in record[3:]}\n",
    "node_dict: Dict[Tuple[float, float], int] = {node_lat_long: idx for idx, node_lat_long in enumerate(node_set)}\n",
    "inv_node_dict: Dict[int, Tuple[float, float]] = {v: k for k,v in node_dict.items()}\n",
    "\n",
    "# we then map back all the edges\n",
    "n_vertices = len(node_set)\n",
    "edge_object_ids = [obj_id for obj_id, _, _, _, _ in edge_data]\n",
    "edges = [[node_dict[start_node], node_dict[end_node]] for _, _, _, start_node, end_node in edge_data]\n",
    "edge_distances = [distance for _, distance, _, _, _ in edge_data]\n",
    "\n",
    "# and we create the highway graph and output it\n",
    "highway_graph = igraph.Graph(n=n_vertices, \n",
    "                             edges=edges, \n",
    "                             edge_attrs={'weight':edge_distances}\n",
    "                            )\n",
    "highway_graph.write_gml(\"../data/transformed/highway.gml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f64f1c1d-e2c5-49f0-b385-1e7d1e0b0a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/transformed/county_to_node_dict.pickle','wb') as fp:\n",
    "    pickle.dump(county_to_node_dict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98b488e8-4047-4ef7-acc7-9f9d919ad597",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/transformed/node_dict.pickle','wb') as fp:\n",
    "    pickle.dump(node_dict, fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
