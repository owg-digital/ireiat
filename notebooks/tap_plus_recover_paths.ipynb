{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run TAP (Dial's algorithm B) and recover sample paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['R_HOME'] = r\"C:\\Program Files\\R\\R-4.3.3\"\n",
    "\n",
    "import time\n",
    "import gc\n",
    "from collections import defaultdict\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from rpy2.robjects.packages import importr\n",
    "from rpy2.robjects import pandas2ri\n",
    "from rpy2 import robjects\n",
    "from rpy2.robjects.conversion import localconverter\n",
    "\n",
    "# Convert pandas.DataFrames to R dataframes automatically.\n",
    "pandas2ri.activate()\n",
    "\n",
    "cpp_routing = importr(\"cppRouting\")\n",
    "r_cpp_parallel = importr(\"RcppParallel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in sample data\n",
    "\n",
    "Some implementations of the TAP like the node numbers to start at 1, not 0.  For example, the 'Greedy' algorithm by Xie and Ni.  The Larmet implementation, [cppRouting](https://github.com/vlarmet/cppRouting), does not care.\n",
    "\n",
    "However, cppRouting does not like loops and parallel arcs, so we eliminate them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = Path(r'C:\\Users\\Marc.Meketon\\OneDrive - MMC\\Documents\\OliverWyman\\DOE_IntermodalRouting')\n",
    "od_df = pd.read_parquet(data_directory / 'tap_highway_tons.parquet')\n",
    "\n",
    "#  'from' is a keyword in Python and makes referring to fields with that name harder.\n",
    "od_df.rename(columns={'from': 'From', 'to': 'To', 'tons': 'Tons'}, inplace=True)\n",
    "\n",
    "# some software would like node numbers to begin with '1'; not the cppRouting code, but others\n",
    "od_df.From += 1\n",
    "od_df.To += 1\n",
    "tap_network_df = pd.read_parquet(data_directory / 'tap_network_dataframe.parquet')\n",
    "\n",
    "# 'head' and 'tail' are pandas functions, so tap_network_df.head does not work to refer to the column\n",
    "#   but tap_network_df.Head can work\n",
    "tap_network_df.rename(columns={'tail': 'Tail', 'head': 'Head'}, inplace=True)\n",
    "tap_network_df.Tail += 1\n",
    "tap_network_df.Head += 1\n",
    "\n",
    "print(f'od_df.shape: {od_df.shape}, tap_network_df.shape: {tap_network_df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tap_network_df = tap_network_df[~tap_network_df.duplicated(subset=['Tail','Head'])]\n",
    "print(f'tap_network_df.shape after removing parallel links: {tap_network_df.shape}')\n",
    "\n",
    "tap_network_df = tap_network_df[tap_network_df.Tail != tap_network_df.Head]\n",
    "print(f'tap_network_df.shape after loop links: {tap_network_df.shape}')\n",
    "\n",
    "tap_network_df['IDX'] = list(range(1, len(tap_network_df) + 1))\n",
    "tap_network_df.set_index(keys='IDX', inplace=True, drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce TAP capacity by 25% so that multiple paths would be possible\n",
    "tap_network_df.capacity *= 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tap_network_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the TAP algorithm and obtain link flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_tap_link_volumes(network_df: pd.DataFrame, ods_df: pd.DataFrame) -> tuple[float, float, int, pd.DataFrame]:\n",
    "    # NOTE:  do not allow parallel edges.  This is a limitation of the cppRouting package\n",
    "    sgr = cpp_routing.makegraph(network_df[[\"Tail\", \"Head\", \"fft\"]],\n",
    "                            directed=True,\n",
    "                            capacity = tap_network_df['capacity'],\n",
    "                            alpha=tap_network_df['alpha'],\n",
    "                            beta=tap_network_df['beta'])\n",
    "    \n",
    "    # save link from/to to link idx dictionary,\n",
    "    link_from_to_2_idx = {(o, d): idx for o, d, idx in network_df[[\"Tail\", \"Head\", \"IDX\"]].to_numpy()}\n",
    "\n",
    "    max_gap = 1e-6   # default value was 0.001\n",
    "    start_time = time.perf_counter()\n",
    "\n",
    "    # we use the **{} way of passing keywords in because the arguement 'from' is reserved word\n",
    "    #  and in this case Python is not happy with using 'from=ods_df.From'\n",
    "    traffic = cpp_routing.assign_traffic(**{'Graph': sgr, \n",
    "                                            'from': ods_df.From,\n",
    "                                            'to': ods_df.To,\n",
    "                                            'demand': ods_df.Tons,\n",
    "                                            'max_gap': max_gap,\n",
    "                                            'algorithm': 'dial',\n",
    "                                            'verbose': True})\n",
    "    elapsed_time = time.perf_counter() - start_time\n",
    "\n",
    "    gap = traffic.rx2('gap')[0]\n",
    "    num_iterations = traffic.rx2('iteration')[0]\n",
    "    with localconverter(robjects.default_converter + pandas2ri.converter):\n",
    "        link_volumes_df = robjects.conversion.rpy2py(traffic.rx2('data'))\n",
    "    link_volumes_df = link_volumes_df.astype({'from': 'int64', 'to': 'int64'})\n",
    "    link_volumes_df['IDX'] = [link_from_to_2_idx[o, d] for o, d in link_volumes_df[[\"from\", \"to\"]].to_numpy()]\n",
    "    link_volumes_df.set_index(keys='IDX', inplace=True, drop=False)\n",
    "\n",
    "    return elapsed_time, gap, num_iterations, link_volumes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elapsed_time, gap, num_iters, link_vol_df = calc_tap_link_volumes(tap_network_df, od_df)\n",
    "print(f'Elapsed time (seconds): {round(elapsed_time,2)}')\n",
    "print(f'gap: {gap}')\n",
    "print(f'number of iterations: {num_iters}')\n",
    "link_vol_df[link_vol_df.flow > 0.0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# place the flows into an array in the order of the links (using IDX as the ordering)\n",
    "tap_flow = np.zeros(len(link_vol_df) + 1)\n",
    "tap_flow[link_vol_df.IDX.to_numpy()] = link_vol_df.flow\n",
    "tap_flow[tap_flow > 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# place the costs into an array in the order of the links.  This is used for speeding up the path costs calculations\n",
    "\n",
    "costs = np.zeros(len(link_vol_df) + 1)\n",
    "costs[link_vol_df.IDX] = link_vol_df.cost\n",
    "costs[[11612, 261, 262, 11581, 3492]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a set of paths, possible some alternate paths as well\n",
    "\n",
    "This section has two parts:\n",
    "  1.  Find one path for each OD using the calculated costs from TAP assignment\n",
    "  2.  For any path going through links whose total flow is greater than the TAP link flow, find an alternate path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ODPath contains the links for a particular path\n",
    "class ODPath:\n",
    "    def __init__(self, orig: int, dest: int, path_cost: float, flow: float, link_path: np.array) -> None:\n",
    "        self.orig = orig\n",
    "        self.dest = dest\n",
    "        self.path_cost = path_cost\n",
    "        self.flow = flow\n",
    "        self.link_path = link_path\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'{self.orig}->{self.dest} ({np.round(self.path_cost,2)},{np.round(self.flow,2)}){self.link_path}'\n",
    "    \n",
    "    @property\n",
    "    def od(self) -> str:\n",
    "        return f'{self.orig}->{self.dest}'\n",
    "    \n",
    "# ODPaths contains a list of paths for the same OD\n",
    "class ODPaths:\n",
    "    def __init__(self, total_demand, initial_od_path) -> None:\n",
    "        self.total_demand = total_demand\n",
    "        self.list_of_paths: list[ODPath] = [initial_od_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a network using the link costs derived from the TAP problem (ftt * (1 + alpha (flow/capacity)^beta))\n",
    "# Then get the shortest path for all the OD's and store them\n",
    "\n",
    "def get_sample_paths(ods_df: pd.DataFrame, link_volumes_df: pd.DataFrame) -> dict[tuple[int, int], ODPaths]:\n",
    "    ret_paths: dict[tuple[int, int], ODPaths] = dict()\n",
    "    # same links as original network, but use the cost that based on the user equilibrium flows\n",
    "    sgr = cpp_routing.makegraph(link_volumes_df[['from', 'to', 'cost']])\n",
    "    od_paths = cpp_routing.get_path_pair(**{'Graph': sgr,\n",
    "                                        'from': ods_df.From,\n",
    "                                        'to': ods_df.To,\n",
    "                                        'algorithm': 'bi'})\n",
    "    link_from_to_2_idx: dict[tuple[int, int], int] = {(o, d): idx for o, d, idx in link_volumes_df[[\"from\", \"to\", \"IDX\"]].to_numpy()}\n",
    "    od_2_flow: dict[tuple[int, int], float] = {(int(o), int(d)): flow for o, d, flow in ods_df[[\"From\", \"To\", \"Tons\"]].to_numpy()}\n",
    "    costs = np.zeros(len(link_volumes_df) + 1)\n",
    "    costs[link_volumes_df.IDX] = link_volumes_df.cost\n",
    "    for idx, o_d in enumerate(od_paths.names):\n",
    "        orig, dest = (int(n) for n in o_d.split('_'))\n",
    "        node_path = [int(n) for n in od_paths[idx]]\n",
    "        link_path = np.array([link_from_to_2_idx[si, sip1] for si, sip1 in zip(node_path[:-1], node_path[1:])])\n",
    "        path_cost = np.sum(costs[link_path])\n",
    "        total_demand = od_2_flow[orig, dest]\n",
    "        ret_paths[orig, dest] = ODPaths(total_demand, ODPath(orig, dest, path_cost, total_demand, link_path))\n",
    "    return ret_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run it.  This gets the first set of paths, one per OD\n",
    "\n",
    "od_paths = get_sample_paths(od_df, link_vol_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute secondary paths\n",
    "\n",
    "Calculate the link flows if each of the paths had the full demand\n",
    "\n",
    "Take away links that have too much flow, and then recalculate the shortest paths on the reduced network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute link flows based on the paths found above\n",
    "\n",
    "def calc_link_flows(paths: dict[tuple[int, int], ODPaths]):\n",
    "    link_flows = np.zeros(len(tap_network_df) + 1)\n",
    "    for od_paths in paths.values():\n",
    "        for path in od_paths.list_of_paths:\n",
    "            link_flows[path.link_path] += path.flow\n",
    "    return link_flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_by_link = calc_link_flows(od_paths)\n",
    "flow_by_link[flow_by_link > 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify all links whose flow is greater than the TAP flow\n",
    "\n",
    "idx_where_flow_violates_tap = np.asarray(flow_by_link > tap_flow + 0.1).nonzero()[0]\n",
    "link_ratios = np.ones(len(tap_network_df) + 1)\n",
    "link_ratios[idx_where_flow_violates_tap] = tap_flow[idx_where_flow_violates_tap] / flow_by_link[idx_where_flow_violates_tap]\n",
    "idx_where_flow_violates_tap_df = pd.DataFrame({'IDX': idx_where_flow_violates_tap, \n",
    "                                               'SP_FLOW': flow_by_link[idx_where_flow_violates_tap],\n",
    "                                               'TAP_FLOW': tap_flow[idx_where_flow_violates_tap],\n",
    "                                               'RATIO': tap_flow[idx_where_flow_violates_tap] / flow_by_link[idx_where_flow_violates_tap]})\n",
    "idx_where_flow_violates_tap_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essentially 'transpose' the od_paths structure so that for each link we know which paths go through it\n",
    "\n",
    "paths_through_links = np.empty(len(tap_network_df) + 1, dtype=object)\n",
    "for idx in range(len(paths_through_links)):\n",
    "    paths_through_links[idx] = []\n",
    "for paths in od_paths.values():\n",
    "    for path in paths.list_of_paths:\n",
    "        for link_idx in path.link_path:\n",
    "            paths_through_links[link_idx].append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify all paths that use those links whose flow is greater than the TAP Flow\n",
    "paths_that_overflow = {path for paths in paths_through_links[idx_where_flow_violates_tap] for path in paths}\n",
    "[path.od for path in paths_that_overflow]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's flow this on a network where the links tap-flow is greater than the shortest path flows\n",
    "#   which means removing links where the path flows are too large\n",
    "\n",
    "reduced_tap_network_df = tap_network_df[~tap_network_df.IDX.isin(idx_where_flow_violates_tap)].copy()\n",
    "reduced_tap_network_df = reduced_tap_network_df.merge(link_vol_df[['from', 'to', 'cost']], left_on=['Tail', 'Head'], right_on=['from', 'to'])\n",
    "reduced_tap_network_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run shortest path on reduced network to find potential secondary paths\n",
    "\n",
    "Any secondary path that is found must have the same path-cost as the first set of paths.\n",
    "\n",
    "It could be that a secondary path has a higher cost - that could occur because we are too aggressive in taking out links, which is due to having not figuring out precisely how to reduce the flows in paths that use those links that have high flow.\n",
    "\n",
    "We only keep those secondary paths whose cost is the same as the primary path.  Right now, if the secondary path should have costs within 1% of the primary path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same links as original network, but use the cost that based on the user equilibrium flows\n",
    "\n",
    "sgr = cpp_routing.makegraph(reduced_tap_network_df[['Tail', 'Head', 'cost']])\n",
    "reduced_od_paths = cpp_routing.get_path_pair(**{'Graph': sgr,\n",
    "                                    'from': [path.orig for path in paths_that_overflow],\n",
    "                                    'to': [path.dest for path in paths_that_overflow],\n",
    "                                    'algorithm': 'bi'})\n",
    "link_from_to_2_idx: dict[tuple[int, int], int] = {(o, d): idx for o, d, idx in reduced_tap_network_df[[\"from\", \"to\", \"IDX\"]].to_numpy()}\n",
    "\n",
    "costs = np.zeros(len(tap_network_df) + 1)\n",
    "costs[reduced_tap_network_df.IDX] = reduced_tap_network_df.cost\n",
    "for idx, o_d in enumerate(reduced_od_paths.names):\n",
    "    orig, dest = (int(n) for n in o_d.split('_'))\n",
    "    node_path = [int(n) for n in reduced_od_paths[idx]]\n",
    "    link_path = np.array([link_from_to_2_idx[si, sip1] for si, sip1 in zip(node_path[:-1], node_path[1:])])\n",
    "    path_cost = np.sum(costs[link_path])\n",
    "    # print(ODPath(orig, dest, path_cost, 0, link_path))\n",
    "    original_path_cost = od_paths[orig, dest].list_of_paths[0].path_cost\n",
    "    relative_difference = (path_cost - original_path_cost)/original_path_cost\n",
    "    print(f'Original path cost: {original_path_cost}, relative difference: {(path_cost - original_path_cost)/original_path_cost}')\n",
    "    if relative_difference <= 0.01:\n",
    "        od_paths[orig, dest].list_of_paths.append(ODPath(orig, dest, path_cost, 0.0, link_path))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
